# 备库长时间延迟
#### coordinator分发
* 不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个worker中
* 同一个事务不能被拆开，必须放到同一个worker中。

#### 并行复制策略
* 按表分发策略
* worker线程维护库名+表名 + 冲突 (该线程修改这个表的事物数目)
* 如果跟所有 worker 都不冲突，coordinator 线程就会把这个事务分配给最空闲的 woker;
* 如果跟多于一个 worker 冲突，coordinator 线程就进入等待状态，直到和这个事务存在冲突关系的 worker 只剩下 1 个；
* 如果只跟一个 worker 冲突，coordinator 线程就会把这个事务分配给这个存在冲突关系的 worker
* 不足 如果碰到热点表，比如所有的更新事务都会涉及到某一个表的时候，所有事务都会被分配到同一个 worker 中，就变成单线程复制了。

#### 按行分发策略
* 如果两个事务没有更新相同的行，它们在备库上可以并行执行。显然，这个模式要求 binlog 格式必须是 row。
* 每个worker的hash表的key是库名 + 表名 + 唯一键的名字 + 唯一的键的值
* 要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；
* 表必须有主键；
* 不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。
* 不足
* 耗费内存。比如一个语句要删除 100 万行数据，这时候 hash 表就要记录 100 万个项。
* 耗费 CPU。解析 binlog，然后计算 hash 值，对于大事务，这个成本还是很高的。

#### 社区并行复制策略
* 按库分发

#### maradb
* 利用特性
* 能够在同一组里提交的事务，一定不会修改同一行；
* 主库上可以并行执行的事务，备库上也一定是可以并行执行的。
* 复制策略
* 在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1；
* commit_id 直接写到 binlog 里面；
* 传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；
* 这一组全部执行完成后，coordinator 再去取下一批。

#### mysql5.7并行复制策略
* LOGICAL_CLOCK
* 同时处于 prepare 状态的事务，在备库执行时是可以并行的；
* 处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。
* binlog_group_commit_sync_delay
* binlog_group_commit_sync_no_delay_count
* 也可以提升从库的复制并发度
* binlog-transaction-dependency-tracking
* COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。
* WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。
* WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。
* 优势
* writeset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量；
* 不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存；
* 由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。
* 